{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<font color='red'>**Introduction:**</font>\n\nHistopathologic cancer detection involves identifying metastatic cancer in pathology scans. The dataset used in this project consists of labeled images, where detections are labeled 1 and absense 0. ","metadata":{}},{"cell_type":"markdown","source":"# <font color='red'>1. EDA\n  </font>","metadata":{}},{"cell_type":"markdown","source":"## <font color='green'>1.1 Image Visualization</font>","metadata":{}},{"cell_type":"code","source":"# Required Libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\n\n# Load train labels\ntrain_labels = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\n# Define dimensions to resize image\nIMG_WIDTH, IMG_HEIGHT = 96, 96\n\ndef resize_image(img_path, target_width=IMG_WIDTH, target_height=IMG_HEIGHT):\n    img = load_img(img_path, target_size=(target_width, target_height))\n    return img_to_array(img)\n\n# Example usage\nsample_path = train_labels['id'].iloc[0]\nresized_img = resize_image(f'../input/histopathologic-cancer-detection/train/{sample_path}.tif')\nprint(f\"Resized Image Shape: {resized_img.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_image(img):\n    return img / 255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_data, temp_data, train_labels, temp_labels = train_test_split(train_labels['id'].values, train_labels['label'].values, test_size=0.2, random_state=42)\nval_data, test_data, val_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.5, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, load_img, img_to_array\nimport matplotlib.pyplot as plt\n\n# Data augmentation configuration\ndatagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential()\n\n# Convolutional layers\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))  # Binary classification\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T00:48:00.462100Z","iopub.execute_input":"2023-10-01T00:48:00.462664Z","iopub.status.idle":"2023-10-01T00:48:03.739040Z","shell.execute_reply.started":"2023-10-01T00:48:00.462633Z","shell.execute_reply":"2023-10-01T00:48:03.738337Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 94, 94, 32)        896       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 47, 47, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 45, 45, 64)        18496     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 22, 22, 64)       0         \n 2D)                                                             \n                                                                 \n conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 10, 10, 128)      0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 12800)             0         \n                                                                 \n dense (Dense)               (None, 512)               6554112   \n                                                                 \n dropout (Dropout)           (None, 512)               0         \n                                                                 \n dense_1 (Dense)             (None, 1)                 513       \n                                                                 \n=================================================================\nTotal params: 6,647,873\nTrainable params: 6,647,873\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-10-01T00:48:03.739951Z","iopub.execute_input":"2023-10-01T00:48:03.740265Z","iopub.status.idle":"2023-10-01T00:48:03.765446Z","shell.execute_reply.started":"2023-10-01T00:48:03.740235Z","shell.execute_reply":"2023-10-01T00:48:03.764587Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_labels_df = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')\ntrain_labels_df['label'] = train_labels_df['label'].astype(str)  # Convert label column to string","metadata":{"execution":{"iopub.status.busy":"2023-10-01T00:48:03.766818Z","iopub.execute_input":"2023-10-01T00:48:03.767415Z","iopub.status.idle":"2023-10-01T00:48:04.060201Z","shell.execute_reply.started":"2023-10-01T00:48:03.767385Z","shell.execute_reply":"2023-10-01T00:48:04.059300Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\ntrain_labels_df['id'] = train_labels_df['id'].apply(lambda x: f\"{x}.tif\")\n\n\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Normalize images\n\nbatch_size = 32\ntrain_steps = 8000 // batch_size  # 8000 images for training\nval_steps = 2000 // batch_size    # 2000 images for validation\n\ntrain_gen = train_datagen.flow_from_dataframe(\n    dataframe=train_labels_df.head(10000),\n    directory='../input/histopathologic-cancer-detection/train/',\n    x_col='id',\n    y_col='label',\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    class_mode='binary',\n    batch_size=batch_size,\n    subset='training'\n)\n\nval_gen = train_datagen.flow_from_dataframe(\n    dataframe=train_labels_df.head(10000),\n    directory='../input/histopathologic-cancer-detection/train/',\n    x_col='id',\n    y_col='label',\n    target_size=(IMG_WIDTH, IMG_HEIGHT),\n    class_mode='binary',\n    batch_size=batch_size,\n    subset='validation'\n)\n\nhistory = model.fit(\n    train_gen,\n    steps_per_epoch=train_steps,\n    validation_data=val_gen,\n    validation_steps=val_steps,\n    epochs=10\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T00:48:04.061426Z","iopub.execute_input":"2023-10-01T00:48:04.061945Z","iopub.status.idle":"2023-10-01T00:51:41.708941Z","shell.execute_reply.started":"2023-10-01T00:48:04.061913Z","shell.execute_reply":"2023-10-01T00:51:41.707985Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Found 8000 validated image filenames belonging to 2 classes.\nFound 2000 validated image filenames belonging to 2 classes.\nEpoch 1/10\n250/250 [==============================] - 45s 141ms/step - loss: 0.5403 - accuracy: 0.7305 - val_loss: 0.5139 - val_accuracy: 0.7576\nEpoch 2/10\n250/250 [==============================] - 13s 53ms/step - loss: 0.4845 - accuracy: 0.7791 - val_loss: 0.4916 - val_accuracy: 0.7772\nEpoch 3/10\n250/250 [==============================] - 13s 51ms/step - loss: 0.4750 - accuracy: 0.7824 - val_loss: 0.4911 - val_accuracy: 0.7742\nEpoch 4/10\n250/250 [==============================] - 14s 54ms/step - loss: 0.4712 - accuracy: 0.7870 - val_loss: 0.5052 - val_accuracy: 0.7646\nEpoch 5/10\n250/250 [==============================] - 12s 48ms/step - loss: 0.4709 - accuracy: 0.7845 - val_loss: 0.4840 - val_accuracy: 0.7828\nEpoch 6/10\n250/250 [==============================] - 12s 50ms/step - loss: 0.4559 - accuracy: 0.7934 - val_loss: 0.4832 - val_accuracy: 0.7762\nEpoch 7/10\n250/250 [==============================] - 13s 51ms/step - loss: 0.4478 - accuracy: 0.8005 - val_loss: 0.4751 - val_accuracy: 0.7812\nEpoch 8/10\n250/250 [==============================] - 12s 49ms/step - loss: 0.4378 - accuracy: 0.8046 - val_loss: 0.4681 - val_accuracy: 0.7873\nEpoch 9/10\n250/250 [==============================] - 13s 51ms/step - loss: 0.4301 - accuracy: 0.8087 - val_loss: 0.4984 - val_accuracy: 0.7727\nEpoch 10/10\n250/250 [==============================] - 12s 47ms/step - loss: 0.4258 - accuracy: 0.8083 - val_loss: 0.4542 - val_accuracy: 0.7939\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n\n# Adjust the val_steps\nval_steps = np.ceil(len(val_gen.classes) / batch_size)\n\n# Predict classes\nval_predictions = model.predict(val_gen, steps=val_steps)\nval_pred_classes = (val_predictions > 0.5).astype(int).flatten()\n\n# True labels\ntrue_labels = val_gen.classes\n\n# Ensure the lengths match\nval_pred_classes = val_pred_classes[:len(true_labels)]\n\n# Calculate metrics\naccuracy = accuracy_score(true_labels, val_pred_classes)\nprecision = precision_score(true_labels, val_pred_classes)\nrecall = recall_score(true_labels, val_pred_classes)\nf1 = f1_score(true_labels, val_pred_classes)\nroc_auc = roc_auc_score(true_labels, val_predictions)\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")dd\nprint(f\"Recall: {recall:.4f}\")dd\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"ROC-AUC: {roc_auc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T00:51:41.710319Z","iopub.execute_input":"2023-10-01T00:51:41.711445Z","iopub.status.idle":"2023-10-01T00:51:44.675378Z","shell.execute_reply.started":"2023-10-01T00:51:41.711409Z","shell.execute_reply":"2023-10-01T00:51:44.674424Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"63/63 [==============================] - 3s 43ms/step\nAccuracy: 0.5335\nPrecision: 0.4102\nRecall: 0.3932\nF1 Score: 0.4015\nROC-AUC: 0.5140\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras-tuner\n\nfrom kerastuner import RandomSearch\nfrom kerastuner.engine.hyperparameters import HyperParameters","metadata":{"execution":{"iopub.status.busy":"2023-10-01T00:51:45.729440Z","iopub.execute_input":"2023-10-01T00:51:45.729972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(hp):\n    model = Sequential()\n    \n    # Convolutional layers\n    model.add(Conv2D(hp.Int('input_units', min_value=32, max_value=64, step=32), (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    for i in range(hp.Int('n_layers', 1, 3)):  # adding between 1 and 3 convolutional layers\n        model.add(Conv2D(hp.Int(f'conv_{i}_units', min_value=32, max_value=64, step=32), (3, 3), activation='relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    # Fully connected layers\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n    \n    optimizer = Adam(learning_rate=hp.Choice('learning_rate', [1e-3, 1e-4]))\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model\n\ntuner = RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=3,  # reduced number of model configurations to test\n    executions_per_trial=1,\n    directory='output',\n    project_name='HistoPathologicCancerDetection'\n)\n\n# Train for fewer epochs during hyperparameter tuning\ntuner.search(train_gen, epochs=5, validation_data=val_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\n\n# Load the VGG16 model with weights pre-trained on ImageNet\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n\n# Freeze the layers of the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Create a custom model on top\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.regularizers import l2\n\n# Load the VGG16 model with weights pre-trained on ImageNet\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n\n# Freeze the layers of the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel = Sequential()\nmodel.add(base_model)\n\n# Convolutional layers\n# Removed pooling layers and adjusted convolutional layers\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.01), padding='same'))\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01), padding='same'))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01), padding='same'))\n\n# Fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu', kernel_regularizer=l2(0.01)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))  # Binary classification\n\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}